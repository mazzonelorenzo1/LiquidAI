{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1vAQgLeBlY0_WI8OtJPOxvxxhuZgTniif",
      "authorship_tag": "ABX9TyNhLGGyGcKDMcni8YrDlFH+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install liquid-audio"
      ],
      "metadata": {
        "id": "Z3V5ibgXSl_A",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"liquid-audio[demo]\""
      ],
      "metadata": {
        "id": "Qh-vMSCsStht",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchcodec"
      ],
      "metadata": {
        "id": "H8ASIt57UXzU",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJZ9VEZDSL5H",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from liquid_audio import LFM2AudioModel, LFM2AudioProcessor, ChatState, LFMModality\n",
        "\n",
        "# Load models\n",
        "HF_REPO = \"LiquidAI/LFM2-Audio-1.5B\"\n",
        "\n",
        "processor = LFM2AudioProcessor.from_pretrained(HF_REPO).eval()\n",
        "model = LFM2AudioModel.from_pretrained(HF_REPO).eval()\n",
        "\n",
        "# Set up inputs for the model\n",
        "chat = ChatState(processor)\n",
        "\n",
        "chat.new_turn(\"system\")\n",
        "chat.add_text(\"Respond_with_interleaved_text_and_audio.\")\n",
        "chat.end_turn()\n",
        "\n",
        "chat.new_turn(\"user\")\n",
        "\n",
        "# Fix the demo file with the proper directory\n",
        "wav, sampling_rate = torchaudio.load(\"/content/Liquid_question.m4a\")\n",
        "\n",
        "# Convert stereo to mono if necessary\n",
        "if wav.shape[0] > 1:\n",
        "    wav = wav.mean(dim=0, keepdim=True)\n",
        "chat.add_audio(wav, sampling_rate)\n",
        "chat.end_turn()\n",
        "\n",
        "chat.new_turn(\"assistant\")\n",
        "\n",
        "# Generate text and audio tokens.\n",
        "text_out: list[torch.Tensor] = []\n",
        "audio_out: list[torch.Tensor] = []\n",
        "modality_out: list[LFMModality] = []\n",
        "for t in model.generate_interleaved(**chat, max_new_tokens=512, audio_temperature=1.0, audio_top_k=4):\n",
        "    if t.numel() == 1:\n",
        "        print(processor.text.decode(t), end=\"\", flush=True)\n",
        "        text_out.append(t)\n",
        "        modality_out.append(LFMModality.TEXT)\n",
        "    else:\n",
        "        audio_out.append(t)\n",
        "        modality_out.append(LFMModality.AUDIO_OUT)\n",
        "\n",
        "# Detokenize audio, removing the last \"end-of-audio\" codes\n",
        "# Mimi returns audio at 24kHz\n",
        "mimi_codes = torch.stack(audio_out[:-1], 1).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    waveform = processor.mimi.decode(mimi_codes)[0]\n",
        "torchaudio.save(\"answer_Liquid.wav\", waveform.cpu(), 24_000)\n",
        "\n",
        "# Append newly generated tokens to chat history\n",
        "chat.append(\n",
        "    text = torch.stack(text_out, 1),\n",
        "    audio_out = torch.stack(audio_out, 1),\n",
        "    modality_flag = torch.tensor(modality_out),\n",
        ")\n",
        "chat.end_turn()\n",
        "\n",
        "# Start second turn\n",
        "chat.new_turn(\"user\")\n",
        "wav, sampling_rate = torchaudio.load(\"/content/GPU_question.m4a\")\n",
        "if wav.shape[0] > 1:\n",
        "    wav = wav.mean(dim=0, keepdim=True)\n",
        "chat.add_audio(wav, sampling_rate)\n",
        "chat.end_turn()\n",
        "\n",
        "chat.new_turn(\"assistant\")\n",
        "\n",
        "# Generate second turn text and audio tokens.\n",
        "audio_out: list[torch.Tensor] = []\n",
        "for t in model.generate_interleaved(**chat, max_new_tokens=512, audio_temperature=1.0, audio_top_k=4):\n",
        "    if t.numel() == 1:\n",
        "        print(processor.text.decode(t), end=\"\", flush=True)\n",
        "    else:\n",
        "        audio_out.append(t)\n",
        "\n",
        "# Detokenize second turn audio, removing the last \"end-of-audio\" codes\n",
        "mimi_codes = torch.stack(audio_out[:-1], 1).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    waveform = processor.mimi.decode(mimi_codes)[0]\n",
        "torchaudio.save(\"answer_GPU.wav\", waveform.cpu(), 24_000)\n",
        "\n",
        "# Start third turn\n",
        "chat.new_turn(\"user\")\n",
        "wav, sampling_rate = torchaudio.load(\"/content/Cuda_error.m4a\")\n",
        "if wav.shape[0] > 1:\n",
        "    wav = wav.mean(dim=0, keepdim=True)\n",
        "chat.add_audio(wav, sampling_rate)\n",
        "chat.end_turn()\n",
        "\n",
        "chat.new_turn(\"assistant\")\n",
        "\n",
        "# Generate third turn text and audio tokens.\n",
        "audio_out: list[torch.Tensor] = []\n",
        "for t in model.generate_interleaved(**chat, max_new_tokens=512, audio_temperature=1.0, audio_top_k=4):\n",
        "    if t.numel() == 1:\n",
        "        print(processor.text.decode(t), end=\"\", flush=True)\n",
        "    else:\n",
        "        audio_out.append(t)\n",
        "\n",
        "# Detokenize third audio, removing the last \"end-of-audio\" codes\n",
        "mimi_codes = torch.stack(audio_out[:-1], 1).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    waveform = processor.mimi.decode(mimi_codes)[0]\n",
        "torchaudio.save(\"answer_Cuda.wav\", waveform.cpu(), 24_000)\n",
        "\n",
        "# Start fourth turn\n",
        "chat.new_turn(\"user\")\n",
        "chat.add_text(\"Okay_I_will_try_with_this_solution_thanks\")\n",
        "chat.end_turn()\n",
        "\n",
        "chat.new_turn(\"assistant\")\n",
        "\n",
        "# Generate fourth turn text and audio tokens.\n",
        "audio_out: list[torch.Tensor] = []\n",
        "for t in model.generate_interleaved(**chat, max_new_tokens=512, audio_temperature=1.0, audio_top_k=4):\n",
        "    if t.numel() == 1:\n",
        "        print(processor.text.decode(t), end=\"\", flush=True)\n",
        "    else:\n",
        "        audio_out.append(t)\n",
        "\n",
        "# Detokenize fourth turn audio, removing the last \"end-of-audio\" codes\n",
        "mimi_codes = torch.stack(audio_out[:-1], 1).unsqueeze(0)\n",
        "with torch.no_grad():\n",
        "    waveform = processor.mimi.decode(mimi_codes)[0]\n",
        "torchaudio.save(\"answer_solution.wav\", waveform.cpu(), 24_000)\n"
      ]
    }
  ]
}